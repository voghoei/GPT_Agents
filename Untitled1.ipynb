{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dac182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
      "  \"id\": \"cmpl-8KwuR26gfyGlPNB96xkLgRDo0LkqY\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1700003699,\n",
      "  \"model\": \"text-davinci-001\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nThis is a test\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"length\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 5,\n",
      "    \"completion_tokens\": 6,\n",
      "    \"total_tokens\": 11\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "prompt = \"Say this is a test\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-001\", prompt=prompt, max_tokens=6\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b031c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "def open_file(filepath):\n",
    "    with open (filepath, 'r', encoding = 'utf-8') as infile:\n",
    "        return infile.read()\n",
    "    \n",
    "def save_file ( filepath, content):\n",
    "    with open (filepath, 'w', encoding = 'utf-8') as outfule:\n",
    "               outfile.write(content)\n",
    "            \n",
    "prompt = open_file('propt.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "442cdcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " QuestionsMy question is should I get the PS4 or XBOX ONE\n",
      "\n",
      "Console wars are a never ending battle that will go on for eternity. The victor is undecided and the spoils are unclaimed. However, if you would like to partake in this glorious struggle, then the PlayStation 4 and the Xbox One are the two consoles for you.\n",
      "\n",
      "Each console has its own advantages and disadvantages, so it is important to consider what is important to you before making a decision. Here is a breakdown of the main pros and cons of each console.\n",
      "\n",
      "PlayStation 4\n",
      "\n",
      "The Pros:\n",
      "\n",
      "1. The PlayStation 4 has a better user interface than the Xbox One.\n",
      "\n",
      "2. The PlayStation 4 has better graphics than the Xbox One.\n",
      "\n",
      "3. The PlayStation 4 is cheaper than the Xbox One.\n",
      "\n",
      "The Cons:\n",
      "\n",
      "1. The PlayStation 4 does not have as many exclusives as the Xbox One.\n",
      "\n",
      "2. The PlayStation 4 is not as powerful as the Xbox One.\n",
      "\n",
      "Xbox One\n",
      "\n",
      "The Pros:\n",
      "\n",
      "1. The Xbox One has a better user interface than the PlayStation 4.\n",
      "\n",
      "2. The Xbox One has better graphics than the PlayStation 4.\n",
      "\n",
      "3. The Xbox One is more powerful than the PlayStation 4.\n",
      "\n",
      "The Cons:\n",
      "\n",
      "1. The Xbox One has less exclusives than the PlayStation 4.\n",
      "\n",
      "2. The Xbox One is more expensive than the PlayStation 4.\n"
     ]
    }
   ],
   "source": [
    "def gpt3(prompt):\n",
    "    response = openai.Completion.create(\n",
    "    model = \"text-davinci-001\",\n",
    "    prompt = prompt,\n",
    "    max_tokens = 500,\n",
    "    top_p = 1,\n",
    "    frequency_penalty = 0,\n",
    "    presence_penalty = 0)\n",
    "    test = response['choices'][0]['text'].strip()\n",
    "    return test\n",
    "\n",
    "prose = gpt3(prompt)\n",
    "print('\\n\\n Questions'+ prose) \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6fd9b77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16472/3640091656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'questions.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprompt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'propt1.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<<QS>>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPT3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\nAnswers:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'answers.txt, answers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16472/1161130820.py\u001b[0m in \u001b[0;36msave_file\u001b[1;34m(filepath, content)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msave_file\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfule\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'propt.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outfile' is not defined"
     ]
    }
   ],
   "source": [
    "save_file('questions.txt', prose)\n",
    "prompt2 = open_file('propt1.txt').replace('<<QS>>', prose)\n",
    "answer = GPT3(prompt2)\n",
    "print('\\n\\nAnswers:', answers)\n",
    "save_file('answers.txt, answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea5d32c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quart'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16472/4037574367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mquart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mquart_cors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mquart\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'quart'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import quart\n",
    "import quart_cors\n",
    "from quart import request\n",
    "\n",
    "# Note: Setting CORS to allow chat.openapi.com is only required when running a localhost plugin\n",
    "app = quart_cors.cors(quart.Quart(__name__), allow_origin=\"https://chat.openai.com\")\n",
    "\n",
    "_TODOS = {}\n",
    "\n",
    "\n",
    "@app.post(\"/todos/<string:username>\")\n",
    "async def add_todo(username):\n",
    "    request = await quart.request.get_json(force=True)\n",
    "    if username not in _TODOS:\n",
    "        _TODOS[username] = []\n",
    "    _TODOS[username].append(request[\"todo\"])\n",
    "    return quart.Response(response='OK', status=200)\n",
    "\n",
    "\n",
    "@app.get(\"/todos/<string:username>\")\n",
    "async def get_todos(username):\n",
    "    return quart.Response(response=json.dumps(_TODOS.get(username, [])), status=200)\n",
    "\n",
    "\n",
    "@app.delete(\"/todos/<string:username>\")\n",
    "async def delete_todo(username):\n",
    "    request = await quart.request.get_json(force=True)\n",
    "    todo_idx = request[\"todo_idx\"]\n",
    "    if 0 <= todo_idx < len(_TODOS[username]):\n",
    "        _TODOS[username].pop(todo_idx)\n",
    "    return quart.Response(response='OK', status=200)\n",
    "\n",
    "\n",
    "@app.get(\"/logo.png\")\n",
    "async def plugin_logo():\n",
    "    filename = 'logo.png'\n",
    "    return await quart.send_file(filename, mimetype='image/png')\n",
    "\n",
    "\n",
    "@app.get(\"/.well-known/ai-plugin.json\")\n",
    "async def plugin_manifest():\n",
    "    host = request.headers['Host']\n",
    "    with open(\"ai-plugin.json\") as f:\n",
    "        text = f.read()\n",
    "        # This is a trick we do to populate the PLUGIN_HOSTNAME constant in the manifest\n",
    "        text = text.replace(\"PLUGIN_HOSTNAME\", f\"https://{host}\")\n",
    "        return quart.Response(text, mimetype=\"text/json\")\n",
    "\n",
    "\n",
    "@app.get(\"/openapi.yaml\")\n",
    "async def openapi_spec():\n",
    "    host = request.headers['Host']\n",
    "    with open(\"openapi.yaml\") as f:\n",
    "        text = f.read()\n",
    "        # This is a trick we do to populate the PLUGIN_HOSTNAME constant in the OpenAPI spec\n",
    "        text = text.replace(\"PLUGIN_HOSTNAME\", f\"https://{host}\")\n",
    "        return quart.Response(text, mimetype=\"text/yaml\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    app.run(debug=True, host=\"0.0.0.0\", port=5002)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82616d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ee44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
